{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knn_e2eml.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOz2m90zUfAraxQi8cMEGlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/au1206/ML-Practice/blob/main/Knn_e2eml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN from scratch \n"
      ],
      "metadata": {
        "id": "tBXbM32V7mjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data\n",
        "Dataset:  Palmer Penguins data set"
      ],
      "metadata": {
        "id": "PkVDW_Hl7rDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsBwcgUu7o5B",
        "outputId": "90edcfa8-0bbe-4bee-95f6-db0e97652fc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 06:06:53--  https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15241 (15K) [text/plain]\n",
            "Saving to: ‘penguins.csv’\n",
            "\n",
            "\rpenguins.csv          0%[                    ]       0  --.-KB/s               \rpenguins.csv        100%[===================>]  14.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-27 06:06:53 (96.6 MB/s) - ‘penguins.csv’ saved [15241/15241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "pQd15qfRxFJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "OmNkqxP2FNwI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the data"
      ],
      "metadata": {
        "id": "hotnCKAyxJ6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('penguins.csv', 'rt') as f:\n",
        "  data = f.readlines()"
      ],
      "metadata": {
        "id": "EmFg-4I-7-Uh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_headers = data[0].split(',')\n",
        "print(column_headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5nBsnMNEHPD",
        "outputId": "0d04fe69-7e58-4a29-8604-7a25f17112fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wI2402NEIF8",
        "outputId": "674b2957-20f7-415d-9586-b150997cb87a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['species,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex,year\\n',\n",
              " 'Adelie,Torgersen,39.1,18.7,181,3750,male,2007\\n',\n",
              " 'Adelie,Torgersen,39.5,17.4,186,3800,female,2007\\n',\n",
              " 'Adelie,Torgersen,40.3,18,195,3250,female,2007\\n',\n",
              " 'Adelie,Torgersen,NA,NA,NA,NA,NA,2007\\n',\n",
              " 'Adelie,Torgersen,36.7,19.3,193,3450,female,2007\\n',\n",
              " 'Adelie,Torgersen,39.3,20.6,190,3650,male,2007\\n',\n",
              " 'Adelie,Torgersen,38.9,17.8,181,3625,female,2007\\n',\n",
              " 'Adelie,Torgersen,39.2,19.6,195,4675,male,2007\\n',\n",
              " 'Adelie,Torgersen,34.1,18.1,193,3475,NA,2007\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label: species, \n",
        "# feature: 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex'\n",
        "def process_data(data):\n",
        "  species = {'Adelie':0 , 'Gentoo': 1, 'Chinstrap': 2}\n",
        "  gender = {'male': 0, 'female': 1}\n",
        "  features = np.zeros((len(data), 5))\n",
        "  labels = np.zeros(len(data))\n",
        "\n",
        "  for id, line in enumerate(data):\n",
        "    line = line.split(',')\n",
        "    try:\n",
        "      feature = [float(x.strip()) for x in line[2:6]]\n",
        "      sex = float(gender[line[6]])\n",
        "      features[id, :4] = feature\n",
        "      features[id, -1] = sex\n",
        "      labels[id] = species[line[0]]\n",
        "\n",
        "\n",
        "    except Exception:\n",
        "      # basically ignoring thhe handling of NA righht now. Since its KNN shouold be fine\n",
        "      pass\n",
        "\n",
        "  return features, labels"
      ],
      "metadata": {
        "id": "dmGWMYJrES2z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = process_data(data)"
      ],
      "metadata": {
        "id": "Sq5i-LWgH2NL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The train test split"
      ],
      "metadata": {
        "id": "f_U7bgEUxQgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(features, labels, frac=0.8):\n",
        "  \"\"\"\n",
        "  function to create the train test splits\n",
        "  Params:\n",
        "  features: processed features obtained after process data call. 2D numpy matrix\n",
        "  labels: processed labels obtained after process data call. 1D numpy matrix\n",
        "  frac: 0-1, defines the train percentage split \n",
        "\n",
        "  Return:\n",
        "  x_train: features for train set\n",
        "  y_train: labels for train set\n",
        "  x_test: features for test set\n",
        "  y_test: labels for test set\n",
        "  \"\"\"\n",
        "  idx = np.arange(features.shape[0])\n",
        "  np.random.shuffle(idx)\n",
        "  n= int(frac*len(idx))\n",
        "  train_id = idx[:n]\n",
        "  test_id = idx[n:]\n",
        "  x_train = features[train_id,:]\n",
        "  y_train = labels[train_id]\n",
        "  x_test = features[test_id,:]\n",
        "  y_test = labels[test_id]\n",
        "\n",
        "  # Feature Scaling: really important for knn and similar algos.\n",
        "  mean = np.mean(x_train, axis=0)\n",
        "  std = np.sqrt(np.var(x_train, axis=0))\n",
        "  x_train = (x_train - mean) / std\n",
        "  x_test = (x_test - mean) / std\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "fskS5_pxIBtd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = train_test_split(features, labels)"
      ],
      "metadata": {
        "id": "lUMVDcakIEGK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of x_train: {x_train.shape}\")\n",
        "print(f\"Size of y_train: {y_train.shape}\")\n",
        "print(f\"Size of x_test: {x_test.shape}\")\n",
        "print(f\"Size of x_test: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_fHmco7M96h",
        "outputId": "e0d66987-8436-48cb-edfb-de6f6d4e8a31"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x_train: (276, 5)\n",
            "Size of y_train: (276,)\n",
            "Size of x_test: (69, 5)\n",
            "Size of x_test: (69,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "742DBEeixUA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class knn():\n",
        "  def __init__(self, k: int):\n",
        "    self.k = k\n",
        "\n",
        "  def predict(self, test_feature, train_features):\n",
        "    \"\"\"\n",
        "    returns the k nearest neighbors\n",
        "    \"\"\"\n",
        "    dist = np.sum(np.abs(train_features - test_feature[np.newaxis, :]),axis=1)\n",
        "    order = np.argsort(dist) # the indices of the nearest neighbors\n",
        "    return order[: self.k]\n",
        "\n",
        "  def score(self, train_labels, test_label):\n",
        "    label_counter = np.zeros(3) # number of classes are 3, can replace with a dict as well\n",
        "    for elem in train_labels:\n",
        "      label_counter[int(elem)]+=1\n",
        "    y_pred = np.argmax(label_counter)  # argmax returns first occurence in case of tie\n",
        "    print(\"Predicted class: \", label_counter, y_pred)\n",
        "    if y_pred == test_label:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def evaluate(self, test_features, train_features, test_labels, train_labels):\n",
        "    total_score = 0\n",
        "    for i in range(len(test_features)):\n",
        "      top_k = self.predict(test_features[i,:], train_features)\n",
        "      score  = self.score(train_labels[top_k], test_labels[i] )\n",
        "      total_score+=score\n",
        "\n",
        "    return total_score/len(test_features)"
      ],
      "metadata": {
        "id": "U0Kk24zsNmO_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls = knn(k=5)"
      ],
      "metadata": {
        "id": "UmjG8CVzkK8a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = cls.evaluate(x_test, x_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii5D2pkPkP-O",
        "outputId": "69d02d9e-8f9e-4c38-da35-577a211079f8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [4. 0. 1.] 0\n",
            "Predicted class:  [3. 0. 2.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [3. 0. 2.] 0\n",
            "Predicted class:  [3. 0. 2.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [3. 0. 2.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [5. 0. 0.] 0\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [0. 0. 5.] 2\n",
            "Predicted class:  [0. 5. 0.] 1\n",
            "Predicted class:  [5. 0. 0.] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The accuracy of our KNN with k=5 is {acc*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNLHIVI0oPOJ",
        "outputId": "da7caf45-79e4-4dce-bf89-5fd69f62c748"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of our KNN with k=5 is 98.55072463768117%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4RSnYWfZo1Of"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}